{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ea30261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "import enchant\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08685a79",
   "metadata": {},
   "source": [
    "# PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e2c86db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(content,U,totalCount):\n",
    "    d={}\n",
    "    words=content.split()\n",
    "    ps = PorterStemmer()\n",
    "    engDict=enchant.Dict(\"en_US\")\n",
    "    for word in words:\n",
    "        if (not word.isalnum()) and (word != '$'):\n",
    "            continue\n",
    "        if word.isnumeric():\n",
    "            value=\"NUMBER\"\n",
    "        else:\n",
    "            value=word.lower()\n",
    "            if engDict.check(value):\n",
    "                value=ps.stem(value)\n",
    "            else:\n",
    "                value=\"UNKNOWN\"\n",
    "        \n",
    "        if(d.get(value) == None):\n",
    "            if U.get(value) == None:\n",
    "                U[value]=totalCount\n",
    "                totalCount+=1\n",
    "            d[value]=1\n",
    "            \n",
    "    \n",
    "    \n",
    "    return d\n",
    "\n",
    "def readData(PATH,spam,U,totalCount):\n",
    "    dirList=os.listdir(PATH)\n",
    "    size=len(dirList)\n",
    "#     print(size)\n",
    "    X=[]\n",
    "    y=[spam for i in range(size)]\n",
    "    c=0\n",
    "    for file in dirList:\n",
    "        with open(PATH+'/'+file, 'r',errors='ignore') as f:\n",
    "#             print(file)\n",
    "            content=f.read()\n",
    "            contentDict=preprocess(content,U,totalCount)\n",
    "#         print(contentDict)\n",
    "        X.append(contentDict)\n",
    "#         if c==10:\n",
    "#             break\n",
    "#         c+=1\n",
    "    return X,y\n",
    "\n",
    "def makeDataStructure(spamX,spamY,U):\n",
    "    m=len(spamX)\n",
    "    d=len(U)\n",
    "    X=np.zeros([d,m])\n",
    "    for i in range(m):\n",
    "        for word in spamX[i]:\n",
    "            if U.get(word) == None:\n",
    "                continue\n",
    "            X[U[word]][i]=spamX[i][word]\n",
    "\n",
    "    return X\n",
    "    \n",
    "        \n",
    "\n",
    "U={}   \n",
    "totalCount=0\n",
    "SPAM_PATH=\"Dataset/enron1/spam\"\n",
    "HAM_PATH=\"Dataset/enron1/ham\"\n",
    "spamX,spamY=readData(SPAM_PATH,1,U,totalCount)\n",
    "hamX,hamY=readData(HAM_PATH,0,U,totalCount)\n",
    "# print(U)\n",
    "\n",
    "# print(X)\n",
    "# listOfWords=list(U)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce7fe688",
   "metadata": {},
   "outputs": [],
   "source": [
    "XSpam=makeDataStructure(spamX,spamY,U)\n",
    "XHam=makeDataStructure(hamX,hamY,U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91053d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XSpam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "594bac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeData(XSpam,XHam,U):\n",
    "    spamfile=open('spam-new', 'wb')\n",
    "    hamfile=open('ham-new', 'wb')\n",
    "    Ufile= open('u-new', 'wb')\n",
    "    \n",
    "    \n",
    "    pickle.dump(XSpam,spamfile)\n",
    "    pickle.dump(XHam,hamfile)\n",
    "    pickle.dump(U, Ufile)\n",
    "    \n",
    "    spamfile.close()\n",
    "    hamfile.close()\n",
    "    Ufile.close()\n",
    "    \n",
    "storeData(XSpam,XHam,U)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b40df7",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3e657f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "import enchant\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c5f275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    spamfile=open('spam-new', 'rb')\n",
    "    hamfile=open('ham-new', 'rb')\n",
    "    Ufile= open('u-new', 'rb')\n",
    "    \n",
    "    U=pickle.load(Ufile)\n",
    "    XSpam=pickle.load(spamfile)\n",
    "    XHam=pickle.load(hamfile)\n",
    "    \n",
    "    spamfile.close()\n",
    "    hamfile.close()\n",
    "    Ufile.close()\n",
    "    \n",
    "    return U,XSpam,XHam\n",
    "\n",
    "U,XSpam,XHam=loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cae943d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21043"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24b20ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeRepresentation(p,mean):\n",
    "    pfile = open('p-new', 'wb')\n",
    "    meanfile = open('mean-new', 'wb')\n",
    "    \n",
    "    pickle.dump(p, pfile)\n",
    "    pickle.dump(mean, meanfile)\n",
    "    \n",
    "    pfile.close()\n",
    "    meanfile.close()\n",
    "    \n",
    "def loadReprsentation():\n",
    "    pfile = open('p-new', 'rb')\n",
    "    meanfile = open('mean-new', 'rb')\n",
    "    Ufile= open('u-new', 'rb')\n",
    "    \n",
    "    p=pickle.load(pfile)\n",
    "    mean=pickle.load(meanfile)\n",
    "    U=pickle.load(Ufile)\n",
    "    \n",
    "    pfile.close()\n",
    "    meanfile.close()\n",
    "    Ufile.close()\n",
    "    \n",
    "    return p,mean,U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7902c42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.concatenate((XHam,XSpam),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bb722e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21043, 2)\n"
     ]
    }
   ],
   "source": [
    "def naiveBayesTraining(spamX,hamX):\n",
    "    spamSize=spamX.shape[1]\n",
    "    hamSize=hamX.shape[1]\n",
    "    size=spamSize+hamSize\n",
    "    mean=np.zeros([spamX.shape[0],2])\n",
    "    p=spamSize/size\n",
    "    \n",
    "    mean[:,1]=np.sum(spamX,axis=1)/spamSize\n",
    "    mean[:,0]=np.sum(hamX,axis=1)/hamSize\n",
    "\n",
    "    \n",
    "    return p,mean\n",
    "\n",
    "d=XSpam.shape[0]\n",
    "ones=np.ones([d,1])\n",
    "\n",
    "\n",
    "# laplace smoothing\n",
    "# XSpam=np.concatenate((XSpam,ones),axis=1)\n",
    "# XHam=np.concatenate((XHam,ones),axis=1)\n",
    "\n",
    "# training\n",
    "p,mean=naiveBayesTraining(XSpam,XHam)\n",
    "print(mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60ce1eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XSpam=np.concatenate((XSpam,ones),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85ca5bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store parameters\n",
    "storeRepresentation(p,mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c02c347",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11e30224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "import enchant\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1534a817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probPart(x,mean):\n",
    "    d=x.shape[0]\n",
    "#     print(mean.shape)\n",
    "    prob=1\n",
    "    count=d**2\n",
    "    for i in range(d):\n",
    "        if x[i] != 0 :\n",
    "            if mean[i] != 0:\n",
    "                prob*=mean[i]\n",
    "            else:\n",
    "                prob*=1/count\n",
    "        else:\n",
    "            if mean[i] != 1:\n",
    "                prob*=(1-mean[i])\n",
    "            else:\n",
    "                prob*=1/count\n",
    "                \n",
    "    return prob\n",
    "            \n",
    "    \n",
    "def naiveBayesPrediction(x,p,mean):\n",
    "    spamProbability=probPart(x,mean[:,1])*p\n",
    "    hamProbability=probPart(x,mean[:,0])*(1-p)\n",
    "    if(spamProbability >= hamProbability):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01be26d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0da97912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadReprsentation():\n",
    "    pfile = open('p-new', 'rb')\n",
    "    meanfile = open('mean-new', 'rb')\n",
    "    Ufile= open('u-new', 'rb')\n",
    "    \n",
    "    p=pickle.load(pfile)\n",
    "    mean=pickle.load(meanfile)\n",
    "    U=pickle.load(Ufile)\n",
    "    \n",
    "    pfile.close()\n",
    "    meanfile.close()\n",
    "    Ufile.close()\n",
    "    \n",
    "    return p,mean,U\n",
    "\n",
    "def testPreprocess(content,U):\n",
    "    words=content.split()\n",
    "    ps = PorterStemmer()\n",
    "    engDict=enchant.Dict(\"en_US\")\n",
    "    d=len(U)\n",
    "    xTest=np.zeros([d,1])\n",
    "    for word in words:\n",
    "        if (not word.isalnum()) and (word != '$'):\n",
    "            continue\n",
    "        if word.isnumeric():\n",
    "            value=\"NUMBER\"\n",
    "        else:\n",
    "            value=word.lower()\n",
    "            if engDict.check(value):\n",
    "                value=ps.stem(value)\n",
    "            else:\n",
    "                value=\"UNKNOWN\"\n",
    "        \n",
    "        if(U.get(value) == None):\n",
    "            continue\n",
    "            \n",
    "        xTest[U[value]][0]+=1\n",
    "                \n",
    "    return xTest\n",
    "\n",
    "def prediction(file,U,p,mean):\n",
    "    content=file.read()\n",
    "    xTest=testPreprocess(content,U)\n",
    "#     print(xTest.shape)\n",
    "#     print(mean.shape)\n",
    "    yPredicted=naiveBayesPrediction(xTest,p,mean)\n",
    "    print(yPredicted)\n",
    "\n",
    "# with open(\"Dataset/enron1/spam/0006.2003-12-18.GP.spam.txt\") as f:\n",
    "#     p,mean,U=loadReprsentation()\n",
    "#     prediction(f,U,p,mean)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08cbe22c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam accuracy :-  0.8155555555555556\n",
      "ham accuracy :-  0.806\n",
      "Overall accuracy :-  0.8131666666666667\n"
     ]
    }
   ],
   "source": [
    "#testing folder\n",
    "TEST_PATH_SPAM=\"Dataset/enron6/spam\"\n",
    "TEST_PATH_HAM=\"Dataset/enron6/ham\"\n",
    "p,mean,U=loadReprsentation()\n",
    "\n",
    "# print(mean)\n",
    "def test(PATH,p,mean,U,spam):\n",
    "    \n",
    "    dirList=os.listdir(PATH)\n",
    "    size=len(dirList)\n",
    "    count=0\n",
    "    c=0\n",
    "    for file in dirList:\n",
    "        with open(PATH+'/'+file, 'r',errors='ignore') as f:\n",
    "                content=f.read()\n",
    "                xTest=testPreprocess(content,U)\n",
    "                yPredicted=naiveBayesPrediction(xTest,p,mean)\n",
    "                count+=yPredicted\n",
    "                \n",
    "#         if c==100:\n",
    "#             break\n",
    "#         c+=1\n",
    "#     size=c\n",
    "#     if spam == 1:\n",
    "#         print(count/size)\n",
    "#     else:\n",
    "#         print(1 - count/size)\n",
    "    return count,size\n",
    "                \n",
    "count1,size1=test(TEST_PATH_SPAM,p,mean,U,1)\n",
    "count2,size2=test(TEST_PATH_HAM,p,mean,U,0) \n",
    "\n",
    "print(\"spam accuracy :- \",count1/size1)\n",
    "print(\"ham accuracy :- \",(size2-count2)/size2)\n",
    "print(\"Overall accuracy :- \",(count1 + size2-count2)/(size1+size2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bf22540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ham2.txt': 1, 'ham1.txt': 0, 'spam1.txt': 1, 'spam3.txt': 0}\n"
     ]
    }
   ],
   "source": [
    "def predictOnTestData(PATH):\n",
    "    p,mean,U=loadReprsentation()\n",
    "    dirList=os.listdir(PATH)\n",
    "    size=len(dirList)\n",
    "    yPredictedDict={}\n",
    "    for file in dirList:\n",
    "        with open(PATH+'/'+file, 'r',errors='ignore') as f:\n",
    "                content=f.read()\n",
    "                xTest=testPreprocess(content,U)\n",
    "                yPredicted=naiveBayesPrediction(xTest,p,mean)\n",
    "                yPredictedDict[file]=yPredicted\n",
    "    \n",
    "    print(yPredictedDict)\n",
    "    \n",
    "PATH=\"test/\"\n",
    "predictOnTestData(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05f2f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
