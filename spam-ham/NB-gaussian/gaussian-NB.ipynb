{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ea30261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "import enchant\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d512519",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e2c86db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(content,U,totalCount):\n",
    "    d={}\n",
    "    words=content.split()\n",
    "    ps = PorterStemmer()\n",
    "    engDict=enchant.Dict(\"en_US\")\n",
    "    for word in words:\n",
    "        \n",
    "        if (not word.isalnum()) and (word != '$'):\n",
    "            continue\n",
    "        if word.isnumeric():\n",
    "            value=\"NUMBER\"\n",
    "        else:\n",
    "            value=word.lower()\n",
    "            if engDict.check(value):\n",
    "                value=ps.stem(value)\n",
    "            else:\n",
    "                value=\"UNKNOWN\"\n",
    "        \n",
    "        if(d.get(value) == None):\n",
    "            U[value]=totalCount\n",
    "            totalCount+=1\n",
    "            d[value]=1\n",
    "        else:\n",
    "            d[value]=d[value]+1\n",
    "            \n",
    "    \n",
    "    \n",
    "    return d\n",
    "\n",
    "def readData(PATH,spam,U,totalCount):\n",
    "    dirList=os.listdir(PATH)\n",
    "    size=len(dirList)\n",
    "#     print(size)\n",
    "    X=[]\n",
    "    y=[spam for i in range(size)]\n",
    "    for file in dirList:\n",
    "        with open(PATH+'/'+file, 'r',errors='ignore') as f:\n",
    "#             print(file)\n",
    "            content=f.read()\n",
    "            contentDict=preprocess(content,U,totalCount)\n",
    "#         print(contentDict)\n",
    "        X.append(contentDict)\n",
    "    return X,y\n",
    "\n",
    "def makeDataStructure(spamX,spamY,U):\n",
    "    m=len(spamX)\n",
    "    d=len(U)\n",
    "    X=np.zeros([d,m])\n",
    "    for i in range(m):\n",
    "        for word in spamX[i]:\n",
    "            if U.get(word) == None:\n",
    "                continue\n",
    "            X[U[word]][i]=spamX[i][word]\n",
    "\n",
    "    return X\n",
    "    \n",
    "        \n",
    "\n",
    "U={}   \n",
    "totalCount=0\n",
    "SPAM_PATH=\"Dataset/enron1/spam\"\n",
    "HAM_PATH=\"Dataset/enron1/ham\"\n",
    "spamX,spamY=readData(SPAM_PATH,1,U,totalCount)\n",
    "hamX,hamY=readData(HAM_PATH,0,U,totalCount)\n",
    "# print(U)\n",
    "\n",
    "# print(X)\n",
    "# listOfWords=list(U)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce7fe688",
   "metadata": {},
   "outputs": [],
   "source": [
    "XSpam=makeDataStructure(spamX,spamY,U)\n",
    "XHam=makeDataStructure(hamX,hamY,U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b559ee1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2219d78",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49fe5509",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "import enchant\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a79fe8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    spamfile=open('spam', 'rb')\n",
    "    hamfile=open('ham', 'rb')\n",
    "    Ufile= open('u', 'rb')\n",
    "    \n",
    "    U=pickle.load(Ufile)\n",
    "    XSpam=pickle.load(spamfile)\n",
    "    XHam=pickle.load(hamfile)\n",
    "    \n",
    "    spamfile.close()\n",
    "    hamfile.close()\n",
    "    Ufile.close()\n",
    "    \n",
    "    return U,XSpam,XHam\n",
    "\n",
    "U,XSpam,XHam=loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24b20ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeRepresentation(p,mean,cov,U):\n",
    "    pfile = open('p', 'ab')\n",
    "    meanfile = open('mean', 'ab')\n",
    "    covfile = open('cov', 'ab')\n",
    "    \n",
    "    pickle.dump(p, pfile)\n",
    "    pickle.dump(mean, meanfile)\n",
    "    pickle.dump(cov, covfile)\n",
    "    \n",
    "    pfile.close()\n",
    "    meanfile.close()\n",
    "    covfile.close()\n",
    "    \n",
    "def loadReprsentation():\n",
    "    pfile = open('p', 'rb')\n",
    "    meanfile = open('mean', 'rb')\n",
    "    covfile = open('cov', 'rb')\n",
    "    Ufile= open('u', 'rb')\n",
    "    \n",
    "    p=pickle.load(pfile)\n",
    "    mean=pickle.load(meanfile)\n",
    "    cov=pickle.load(covfile)\n",
    "    U=pickle.load(Ufile)\n",
    "    \n",
    "    pfile.close()\n",
    "    meanfile.close()\n",
    "    covfile.close()\n",
    "    Ufile.close()\n",
    "    \n",
    "    return p,mean,cov,U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7902c42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  1., ...,  1.,  1., 32.],\n",
       "       [10., 24.,  1., ...,  5.,  1.,  1.],\n",
       "       [ 1.,  1.,  0., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bb722e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayesTraining(spamX,hamX):\n",
    "    spamSize=spamX.shape[1]\n",
    "    hamSize=hamX.shape[1]\n",
    "    size=hamX.shape[1]+spamX.shape[1]\n",
    "    mean=np.zeros([spamX.shape[0],2])\n",
    "    data=np.concatenate((spamX,hamX),axis=1)\n",
    "    p=spamSize/size\n",
    "    mean[:,0]=np.sum(spamX,axis=1)/spamSize\n",
    "    mean[:,1]=np.sum(hamX,axis=1)/hamSize\n",
    "    cov=(data@data.transpose())/size\n",
    "    \n",
    "    \n",
    "    return p,mean,cov\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d20f1a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "storeRepresentation(p,mean,cov,U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f0d3de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7d8c9e7",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc42f902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "import enchant\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1534a817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussianPart(x,mean,cov):\n",
    "    \n",
    "    d=cov.shape[0]\n",
    "    print(x.shape)\n",
    "    print(mean.shape)\n",
    "    mean=mean.reshape(d,1)\n",
    "    sub=x-mean\n",
    "    print(sub.shape)\n",
    "    sub=sub.reshape(d,1)\n",
    "    expTerm=-(sub@np.linalg.pinv(cov)@(sub.transpose()))\n",
    "#     expTerm=-(sub@(sub.transpose()))\n",
    "    return np.exp(expTerm)\n",
    "\n",
    "def naiveBayesPrediction(x,p,mean,cov):\n",
    "    spamProbability=gaussianPart(x,mean[:,1],cov)*p\n",
    "    hamProbability=gaussianPart(x,mean[:,0],cov)*(1-p)\n",
    "    if(spamProbability >= hamProbability):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01be26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadReprsentation():\n",
    "    pfile = open('p', 'rb')\n",
    "    meanfile = open('mean', 'rb')\n",
    "    covfile = open('cov', 'rb')\n",
    "    Ufile= open('u', 'rb')\n",
    "    \n",
    "    p=pickle.load(pfile)\n",
    "    mean=pickle.load(meanfile)\n",
    "    cov=pickle.load(covfile)\n",
    "    U=pickle.load(Ufile)\n",
    "    \n",
    "    pfile.close()\n",
    "    meanfile.close()\n",
    "    covfile.close()\n",
    "    Ufile.close()\n",
    "    \n",
    "    return p,mean,cov,U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da97912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14054, 1)\n",
      "(14054,)\n",
      "(14054, 1)\n",
      "(14054, 1)\n",
      "(14054,)\n",
      "(14054, 1)\n"
     ]
    }
   ],
   "source": [
    "def testPreprocess(content,U):\n",
    "    words=content.split()\n",
    "    ps = PorterStemmer()\n",
    "    engDict=enchant.Dict(\"en_US\")\n",
    "    d=len(U)\n",
    "    xTest=np.zeros([d,1])\n",
    "    for word in words:\n",
    "        if (not word.isalnum()) and (word != '$'):\n",
    "            continue\n",
    "        if word.isnumeric():\n",
    "            value=\"NUMBER\"\n",
    "        else:\n",
    "            value=word.lower()\n",
    "            if engDict.check(value):\n",
    "                value=ps.stem(value)\n",
    "            else:\n",
    "                value=\"UNKNOWN\"\n",
    "        \n",
    "        if(U.get(value) == None):\n",
    "            continue\n",
    "            \n",
    "        xTest[U[value]][0]+=1\n",
    "                \n",
    "    return xTest\n",
    "\n",
    "def prediction(file,U,p,mean,cov):\n",
    "    content=file.read()\n",
    "    xTest=testPreprocess(content,U)\n",
    "#     print(xTest.shape)\n",
    "#     print(mean.shape)\n",
    "    yPredicted=naiveBayesPrediction(xTest,p,mean,cov)\n",
    "    print(yPredicted)\n",
    "\n",
    "with open(\"Dataset/enron1/spam/0006.2003-12-18.GP.spam.txt\") as f:\n",
    "    p,mean,cov,U=loadReprsentation()\n",
    "    prediction(f,U,p,mean,cov)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08cbe22c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3750141197.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [6]\u001b[0;36m\u001b[0m\n\u001b[0;31m    jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "p,mean,cov=naiveBayesTraining(XSpam,XHam)\n",
    "cov=np.dot(np.identity(cov.shape[0]),cov)\n",
    "\n",
    "#testing folder\n",
    "TEST_PATH_SPAM=\"Dataset/enron6/spam\"\n",
    "TEST_PATH_HAM=\"Dataset/enron6/ham\"\n",
    "p,mean,U=loadReprsentation()\n",
    "\n",
    "def test(PATH,p,mean,cov,U,spam):\n",
    "    \n",
    "    dirList=os.listdir(PATH)\n",
    "    size=len(dirList)\n",
    "    count=0\n",
    "    for file in dirList:\n",
    "        with open(PATH+'/'+file, 'r',errors='ignore') as f:\n",
    "                content=f.read()\n",
    "                xTest=testPreprocess(content,U)\n",
    "                yPredicted=naiveBayesPrediction(xTest,p,mean,cov)\n",
    "                count+=yPredicted\n",
    "    if spam == 1:\n",
    "        print(count/size)\n",
    "    else:\n",
    "        print(1 - count/size)\n",
    "                \n",
    "test(TEST_PATH_SPAM,p,mean,cov,U,1)\n",
    "test(TEST_PATH_HAM,p,mean,cov,U,1)      \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
