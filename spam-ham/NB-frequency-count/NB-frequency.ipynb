{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ea30261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "import enchant\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08685a79",
   "metadata": {},
   "source": [
    "# PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e2c86db",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 68>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m SPAM_PATH\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset/enron1/spam\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m HAM_PATH\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset/enron1/ham\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 68\u001b[0m spamX,spamY\u001b[38;5;241m=\u001b[39m\u001b[43mreadData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSPAM_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mU\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtotalCount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m hamX,hamY\u001b[38;5;241m=\u001b[39mreadData(HAM_PATH,\u001b[38;5;241m0\u001b[39m,U,totalCount)\n",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36mreadData\u001b[0;34m(PATH, spam, U, totalCount)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(PATH\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mfile, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m,errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m#             print(file)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m             content\u001b[38;5;241m=\u001b[39mf\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m---> 42\u001b[0m             contentDict\u001b[38;5;241m=\u001b[39m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43mU\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtotalCount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m#         print(contentDict)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m         X\u001b[38;5;241m.\u001b[39mappend(contentDict)\n",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36mpreprocess\u001b[0;34m(content, U, totalCount)\u001b[0m\n\u001b[1;32m      3\u001b[0m words\u001b[38;5;241m=\u001b[39mcontent\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m      4\u001b[0m ps \u001b[38;5;241m=\u001b[39m PorterStemmer()\n\u001b[0;32m----> 5\u001b[0m engDict\u001b[38;5;241m=\u001b[39m\u001b[43menchant\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men_US\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m word\u001b[38;5;241m.\u001b[39misalnum()) \u001b[38;5;129;01mand\u001b[39;00m (word \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/enchant/__init__.py:542\u001b[0m, in \u001b[0;36mDict.__init__\u001b[0;34m(self, tag, broker)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_broker \u001b[38;5;241m=\u001b[39m broker\n\u001b[1;32m    541\u001b[0m \u001b[38;5;66;03m# Now let the superclass initialise the C-library object\u001b[39;00m\n\u001b[0;32m--> 542\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/enchant/__init__.py:144\u001b[0m, in \u001b[0;36m_EnchantObject.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m#  To be importable when enchant C lib is missing, we need\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m#  to create a dummy default broker.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _e \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_this\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/enchant/__init__.py:549\u001b[0m, in \u001b[0;36mDict._init_this\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_this \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtag:\n\u001b[0;32m--> 549\u001b[0m     this \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_broker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_dict_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_this(this, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_broker)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/enchant/__init__.py:283\u001b[0m, in \u001b[0;36mBroker._request_dict_data\u001b[0;34m(self, tag)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m\"\"\"Request raw C pointer data for a dictionary.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[1;32m    279\u001b[0m \u001b[38;5;124;03mThis method call passes on the call to the C library, and does\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;124;03msome internal bookkeeping.\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_this()\n\u001b[0;32m--> 283\u001b[0m new_dict \u001b[38;5;241m=\u001b[39m \u001b[43m_e\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroker_request_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_this\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtag\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    285\u001b[0m     e_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDictionary for language \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m could not be found\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def preprocess(content,U,totalCount):\n",
    "    d={}\n",
    "    words=content.split()\n",
    "    ps = PorterStemmer()\n",
    "    engDict=enchant.Dict(\"en_US\")\n",
    "    for word in words:\n",
    "        \n",
    "        if (not word.isalnum()) and (word != '$'):\n",
    "            continue\n",
    "        if word.isnumeric():\n",
    "            value=\"NUMBER\"\n",
    "        else:\n",
    "            value=word.lower()\n",
    "            if engDict.check(value):\n",
    "                value=ps.stem(value)\n",
    "            else:\n",
    "                value=\"UNKNOWN\"\n",
    "        \n",
    "        if(d.get(value) == None):\n",
    "            if U.get(value) == None:\n",
    "                U[value]=totalCount\n",
    "                totalCount+=1\n",
    "            d[value]=1\n",
    "        else:\n",
    "            d[value]=d[value]+1\n",
    "            \n",
    "    \n",
    "    \n",
    "    return d\n",
    "\n",
    "def readData(PATH,spam,U,totalCount):\n",
    "    dirList=os.listdir(PATH)\n",
    "    size=len(dirList)\n",
    "#     print(size)\n",
    "    X=[]\n",
    "    y=[spam for i in range(size)]\n",
    "    c=0\n",
    "    for file in dirList:\n",
    "        with open(PATH+'/'+file, 'r',errors='ignore') as f:\n",
    "#             print(file)\n",
    "            content=f.read()\n",
    "            contentDict=preprocess(content,U,totalCount)\n",
    "#         print(contentDict)\n",
    "        X.append(contentDict)\n",
    "#         if c==10:\n",
    "#             break\n",
    "#         c+=1\n",
    "    return X,y\n",
    "\n",
    "def makeDataStructure(spamX,spamY,U):\n",
    "    m=len(spamX)\n",
    "    d=len(U)\n",
    "    X=np.zeros([d,m])\n",
    "    for i in range(m):\n",
    "        for word in spamX[i]:\n",
    "            if U.get(word) == None:\n",
    "                continue\n",
    "            X[U[word]][i]=spamX[i][word]\n",
    "\n",
    "    return X\n",
    "    \n",
    "        \n",
    "\n",
    "U={}   \n",
    "totalCount=0\n",
    "SPAM_PATH=\"Dataset/enron1/spam\"\n",
    "HAM_PATH=\"Dataset/enron1/ham\"\n",
    "spamX,spamY=readData(SPAM_PATH,1,U,totalCount)\n",
    "hamX,hamY=readData(HAM_PATH,0,U,totalCount)\n",
    "# print(U)\n",
    "\n",
    "# print(X)\n",
    "# listOfWords=list(U)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7fe688",
   "metadata": {},
   "outputs": [],
   "source": [
    "XSpam=makeDataStructure(spamX,spamY,U)\n",
    "XHam=makeDataStructure(hamX,hamY,U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91053d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "XSpam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79fe8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeData(XSpam,XHam,U):\n",
    "    spamfile=open('spam', 'wb')\n",
    "    hamfile=open('ham', 'wb')\n",
    "    Ufile= open('u', 'wb')\n",
    "    \n",
    "    \n",
    "    pickle.dump(XSpam,spamfile)\n",
    "    pickle.dump(XHam,hamfile)\n",
    "    pickle.dump(U, Ufile)\n",
    "    \n",
    "    spamfile.close()\n",
    "    hamfile.close()\n",
    "    Ufile.close()\n",
    "    \n",
    "# storeData(XSpam,XHam,U)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b40df7",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e657f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "import enchant\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5f275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    spamfile=open('spam', 'rb')\n",
    "    hamfile=open('ham', 'rb')\n",
    "    Ufile= open('u', 'rb')\n",
    "    \n",
    "    U=pickle.load(Ufile)\n",
    "    XSpam=pickle.load(spamfile)\n",
    "    XHam=pickle.load(hamfile)\n",
    "    \n",
    "    spamfile.close()\n",
    "    hamfile.close()\n",
    "    Ufile.close()\n",
    "    \n",
    "    return U,XSpam,XHam\n",
    "\n",
    "U,XSpam,XHam=loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae943d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b20ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeRepresentation(p,mean):\n",
    "    pfile = open('p', 'wb')\n",
    "    meanfile = open('mean', 'wb')\n",
    "    \n",
    "    pickle.dump(p, pfile)\n",
    "    pickle.dump(mean, meanfile)\n",
    "    \n",
    "    pfile.close()\n",
    "    meanfile.close()\n",
    "    \n",
    "def loadReprsentation():\n",
    "    pfile = open('p-f', 'rb')\n",
    "    meanfile = open('mean-f', 'rb')\n",
    "    Ufile= open('u', 'rb')\n",
    "    \n",
    "    p=pickle.load(pfile)\n",
    "    mean=pickle.load(meanfile)\n",
    "    U=pickle.load(Ufile)\n",
    "    \n",
    "    pfile.close()\n",
    "    meanfile.close()\n",
    "    Ufile.close()\n",
    "    \n",
    "    return p,mean,U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7902c42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.concatenate((XHam,XSpam),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb722e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayesTraining(spamX,hamX):\n",
    "    spamSize=np.sum(np.sum(spamX))\n",
    "    hamSize=np.sum(np.sum(hamX))\n",
    "    size=hamX.shape[1]+spamX.shape[1]\n",
    "    mean=np.zeros([spamX.shape[0],2])\n",
    "    p=spamSize/(spamSize+hamSize)\n",
    "    mean[:,1]=np.sum(spamX,axis=1)/spamSize\n",
    "    mean[:,0]=np.sum(hamX,axis=1)/hamSize\n",
    "\n",
    "    \n",
    "    return p,mean\n",
    "\n",
    "d=XSpam.shape[0]\n",
    "# ones=np.ones([d,1])\n",
    "\n",
    "\n",
    "# laplace smoothing\n",
    "# XSpam=np.concatenate((XSpam,ones),axis=1)\n",
    "# XHam=np.concatenate((XHam,ones),axis=1)\n",
    "\n",
    "# training\n",
    "p,mean=naiveBayesTraining(XSpam,XHam)\n",
    "print(mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60ce1eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XSpam=np.concatenate((XSpam,ones),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85ca5bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#store parameters\n",
    "storeRepresentation(p,mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c02c347",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11e30224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "import enchant\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1534a817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probPart(x,mean):\n",
    "    d=x.shape[0]\n",
    "#     print(mean.shape)\n",
    "    prob=1\n",
    "    count=10000000000\n",
    "    for i in range(d):\n",
    "        if x[i] != 0 :\n",
    "            if mean[i] != 0:\n",
    "                prob*=x[i]*mean[i]\n",
    "            else:\n",
    "                prob*=(1/count)\n",
    "                \n",
    "        else:\n",
    "            if mean[i] != 1:\n",
    "                prob*=(1-mean[i])\n",
    "            else:\n",
    "                prob*=1/count\n",
    "                \n",
    "    return prob\n",
    "            \n",
    "    \n",
    "def naiveBayesPrediction(x,p,mean):\n",
    "    spamProbability=probPart(x,mean[:,1])*p\n",
    "    hamProbability=probPart(x,mean[:,0])*(1-p)\n",
    "    if(spamProbability >= hamProbability):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e01be26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracyMeasure():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0da97912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadReprsentation():\n",
    "    pfile = open('p', 'rb')\n",
    "    meanfile = open('mean', 'rb')\n",
    "    Ufile= open('u', 'rb')\n",
    "    \n",
    "    p=pickle.load(pfile)\n",
    "    mean=pickle.load(meanfile)\n",
    "    U=pickle.load(Ufile)\n",
    "    \n",
    "    pfile.close()\n",
    "    meanfile.close()\n",
    "    Ufile.close()\n",
    "    \n",
    "    return p,mean,U\n",
    "\n",
    "def testPreprocess(content,U):\n",
    "    words=content.split()\n",
    "    ps = PorterStemmer()\n",
    "    engDict=enchant.Dict(\"en_US\")\n",
    "    d=len(U)\n",
    "    xTest=np.zeros([d,1])\n",
    "    for word in words:\n",
    "        if (not word.isalnum()) and (word != '$'):\n",
    "            continue\n",
    "        if word.isnumeric():\n",
    "            value=\"NUMBER\"\n",
    "        else:\n",
    "            value=word.lower()\n",
    "            if engDict.check(value):\n",
    "                value=ps.stem(value)\n",
    "            else:\n",
    "                value=\"UNKNOWN\"\n",
    "        \n",
    "        if(U.get(value) == None):\n",
    "            continue\n",
    "            \n",
    "        xTest[U[value]][0]+=1\n",
    "                \n",
    "    return xTest\n",
    "\n",
    "def prediction(file,U,p,mean):\n",
    "    content=file.read()\n",
    "    xTest=testPreprocess(content,U)\n",
    "#     print(xTest.shape)\n",
    "#     print(mean.shape)\n",
    "    yPredicted=naiveBayesPrediction(xTest,p,mean)\n",
    "    print(yPredicted)\n",
    "\n",
    "# with open(\"Dataset/enron1/spam/0006.2003-12-18.GP.spam.txt\") as f:\n",
    "#     p,mean,U=loadReprsentation()\n",
    "#     prediction(f,U,p,mean)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08cbe22c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam accuracy :-  0.9817777777777777\n",
      "ham accuracy :-  0.568\n",
      "Overall accuracy :-  0.8783333333333333\n"
     ]
    }
   ],
   "source": [
    "#testing folder\n",
    "TEST_PATH_SPAM=\"Dataset/enron6/spam\"\n",
    "TEST_PATH_HAM=\"Dataset/enron6/ham\"\n",
    "p,mean,U=loadReprsentation()\n",
    "\n",
    "# print(mean)\n",
    "def test(PATH,p,mean,U,spam):\n",
    "    \n",
    "    dirList=os.listdir(PATH)\n",
    "    size=len(dirList)\n",
    "    count=0\n",
    "    c=0\n",
    "    for file in dirList:\n",
    "        with open(PATH+'/'+file, 'r',errors='ignore') as f:\n",
    "                content=f.read()\n",
    "                xTest=testPreprocess(content,U)\n",
    "                yPredicted=naiveBayesPrediction(xTest,p,mean)\n",
    "                count+=yPredicted\n",
    "                \n",
    "#         if c==100:\n",
    "#             break\n",
    "#         c+=1\n",
    "#     size=c\n",
    "#     if spam == 1:\n",
    "#         print(count/size)\n",
    "#     else:\n",
    "#         print(1 - count/size)\n",
    "    return count,size\n",
    "                \n",
    "count1,size1=test(TEST_PATH_SPAM,p,mean,U,1)\n",
    "count2,size2=test(TEST_PATH_HAM,p,mean,U,0) \n",
    "\n",
    "print(\"spam accuracy :- \",count1/size1)\n",
    "print(\"ham accuracy :- \",(size2-count2)/size2)\n",
    "print(\"Overall accuracy :- \",(count1 + size2-count2)/(size1+size2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b33aeb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ham2.txt': 1, 'ham1.txt': 1, 'spam1.txt': 1, 'spam3.txt': 1}\n"
     ]
    }
   ],
   "source": [
    "def predictOnTestData(PATH):\n",
    "    p,mean,U=loadReprsentation()\n",
    "    dirList=os.listdir(PATH)\n",
    "    size=len(dirList)\n",
    "    yPredictedDict={}\n",
    "    for file in dirList:\n",
    "        with open(PATH+'/'+file, 'r',errors='ignore') as f:\n",
    "                content=f.read()\n",
    "                xTest=testPreprocess(content,U)\n",
    "                yPredicted=naiveBayesPrediction(xTest,p,mean)\n",
    "                yPredictedDict[file]=yPredicted\n",
    "    \n",
    "    print(yPredictedDict)\n",
    "    \n",
    "PATH=\"test/\"\n",
    "predictOnTestData(PATH)\n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca5a1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
